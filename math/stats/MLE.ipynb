{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimations\n",
    "\n",
    "## Bias\n",
    "\n",
    "Let $X_1, \\ldots, X_n$ be an i.i.d. sample from some distribution $F_\\theta(x)$.\n",
    "Estimation $\\widehat\\theta = \\widehat\\theta (X_1, \\ldots, X_n)$ of $\\theta$ is called **unbiased** if \n",
    "$\\mathbb E \\widehat\\theta = \\theta$. Otherwise $\\widehat\\theta$ is called **biased**, and its bias equals to\n",
    "\n",
    "$$\n",
    "\\mathrm{bias}(\\widehat \\theta) = \\mathbb E \\widehat\\theta - \\theta.\n",
    "$$\n",
    "\n",
    "For example, sample average $\\widehat\\theta = \\overline X_n$ is unbiased estimate of mean $\\theta$ since\n",
    "\n",
    "$$\n",
    "    \\mathbb E \\overline{X}_n = \\frac 1n \\sum\\limits_{k = 1}^n \\mathbb E X_k = \\frac 1n\\cdot n\\theta = \\theta.\n",
    "$$\n",
    "\n",
    "Sometimes estimation $\\widehat\\theta_n = \\widehat\\theta(X_1, \\dots, X_n)$ is biased, but this bias vanishes as $n$ becomes large. If $\\lim\\limits_{n\\to\\infty} \\mathbb E\\widehat\\theta_n = \\theta$, then estimation $\\widehat\\theta_n$ is called **asymptotically unbiased**.\n",
    "\n",
    "## Consistency\n",
    "\n",
    "Estimation $\\widehat\\theta_n = \\widehat\\theta(X_1, \\dots, X_n)$ is called **consistent** if it converges to $\\theta$ in distribution: $\\widehat\\theta_n \\stackrel{P}{\\to} \\theta$, i.e.,\n",
    "\n",
    "$$\n",
    "  \\lim\\limits_{n \\to \\infty} \\mathbb{P}(|\\widehat\\theta_n - \\theta| > \\varepsilon) = 0 \\text{ for all } \\varepsilon > 0.\n",
    "$$\n",
    "\n",
    "Due to the law of large numbers $\\widehat\\theta = \\overline{X}_n$ is a consistent estimation for expectation $\\theta = \\mathbb EX_1$ for any i.i.d. sample $X_1, \\ldots, X_n$.\n",
    "\n",
    "## Bias-variance decomposition\n",
    "\n",
    "**Mean squared error** (**MSE**) of $\\widehat{\\theta}$ is\n",
    "\n",
    "$$\n",
    "\\mathrm{MSE}(\\widehat{\\theta}) = \\mathbb{E}(\\widehat{\\theta} - \\theta)^2.\n",
    "$$\n",
    "\n",
    "**Bias-variance decomposition**:\n",
    "\n",
    "$$\n",
    "\\mathrm{MSE}(\\widehat{\\theta}) = \\text{bias}^2(\\widehat{\\theta}) + \\mathbb{V}(\\widehat{\\theta}).\n",
    "$$\n",
    "\n",
    "```{admonition} Proof\n",
    ":class: dropdown\n",
    "\n",
    "$$\n",
    "\\begin{multline*}\n",
    "\\mathrm{MSE}(\\widehat{\\theta}) = \\mathbb{E}(\\widehat{\\theta} - \\theta)^2 =\n",
    "\\mathbb{E}\\big(\\widehat{\\theta} - \\mathbb E\\widehat\\theta + \\mathbb E\\widehat\\theta  - \\theta\\big)^2=\\\\\n",
    "=\\mathbb{E}\\big(\\widehat{\\theta} - \\mathbb E\\widehat\\theta\\big)^2 + 2\\mathbb{E}(\\widehat{\\theta} - \\mathbb E\\widehat\\theta)(\\mathbb E\\widehat\\theta - \\theta) + \n",
    "\\mathbb{E}\\big(\\mathbb E\\widehat\\theta - \\theta\\big)^2 = \\\\\n",
    "  = \\mathbb{V}(\\widehat{\\theta})  + 2\\big(\\underbrace{\\mathbb{E}\\widehat{\\theta} - \\mathbb E\\widehat\\theta}_{=0}\\big)\\big(\\mathbb E\\widehat\\theta - \\theta\\big) + \\mathrm{bias}^2(\\widehat{\\theta}).\n",
    "\\end{multline*}\n",
    "$$\n",
    "```\n",
    "\n",
    "If $\\lim\\limits_{n\\to\\infty}\\mathrm{MSE}(\\widehat{\\theta}_n) = 0$, then estimation $\\widehat{\\theta}_n$ of $\\theta$ asymptotically unbiased and consistent.\n",
    "\n",
    "## Asymptotic normality\n",
    "\n",
    "Estimation $\\widehat{\\theta}_n$ is **asymptotically normal** if $\\frac{\\widehat{\\theta}_n - \\theta}{\\mathrm{se}(\\widehat{\\theta}_n)} \\stackrel{D}{\\to} \\mathcal N(0,1)$, i.e.,\n",
    "\n",
    "$$\n",
    "    \\lim\\limits_{n\\to\\infty}\\mathbb P\\bigg(\\frac{\\widehat{\\theta}_n - \\theta}{\\mathrm{se}(\\widehat{\\theta}_n)} \\leqslant z\\bigg) = \\mathbb \\Phi(z), \\quad \\mathrm{se}(\\widehat{\\theta}_n) = \\sqrt{\\mathbb V\\widehat{\\theta}_n}.\n",
    "$$\n",
    "\n",
    "If $X_1, \\ldots, X_n$ is an i.i.d. sample from some distribution with finite expection $\\mu$ and variance $\\sigma^2$, then according to the central limit theorem $\\overline X_n$ is asymptotically normal estimation of $\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum likelihood estimation (MLE)\n",
    "\n",
    "Let i.i.d. sample $X_1, \\ldots, X_n \\sim F_\\theta(x)$. \n",
    "**Правдоподобие** (**функция правдоподобия**, **likelihood**) выборки $X_1,\\ldots, \\ldots X_n$ — это просто её совместная pmf или pdf. Вне зависимости от типа распределения будем обозначать правдоподобие как \n",
    "\n",
    "$$\n",
    "\\mathcal L(\\theta) \\equiv L(X_1, \\ldots, X_n \\vert \\theta) = p(X_1, \\ldots, X_n \\vert \\theta).\n",
    "$$\n",
    "\n",
    "Если выборка i.i.d., то функция правдоподобия распадается в произведение одномерных функций:\n",
    "\n",
    "$$\n",
    "L(X_1, \\ldots, X_n \\vert \\theta) = \\prod\\limits_{k=1}^n \\log p(X_k\\vert \\theta). \n",
    "$$\n",
    "\n",
    "**Оценка максимального правдоподобия** (**maximum likelihood estimation**, **MLE**) максимизирует правдоподобие:\n",
    "\n",
    "$$\n",
    "    \\widehat \\theta_{\\mathrm{ML}} =  \\arg \\max\\limits_{\\theta} \\mathcal L(\\theta)\n",
    "$$\n",
    "\n",
    "Поскольку максимизировать сумму проще, чем произведение, обычно переходят к логарифму правдоподобия (**log-likelihood**). Это особенно удобно в случае i.i.d. выборки, тогда\n",
    "\n",
    "$$\n",
    "    \\widehat \\theta_{\\mathrm{ML}} =  \\arg \\max\\limits_{\\theta} \\log \\mathcal L(\\theta) =\n",
    "    \\arg \\max\\limits_{\\theta} \\sum\\limits_{k=1}^n p(X_k\\vert \\theta).\n",
    "$$\n",
    "\n",
    "**Properties of MLE**\n",
    "\n",
    "* consistency: $\\widehat \\theta_{\\mathrm{ML}} \\stackrel{P}{\\to} \\theta$;\n",
    "* equivariance: if $\\widehat \\theta_{\\mathrm{ML}}$ — MLE for $\\theta$ then $\\varphi(\\theta)$ — MLE for $\\varphi(\\theta)$;\n",
    "* asymptotic normality: $\\frac{\\widehat \\theta_{\\mathrm{ML}} - \\theta}{\\widehat{\\mathrm{se}}} \\stackrel{D}{\\to} \\mathcal N(0,1)$;\n",
    "* асимптотическая оптимальность: при достаточно больших $n$ оценка \n",
    "$\\widehat \\theta_{\\mathrm{ML}}$ имеет минимальную дисперсию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Let $X_1, \\ldots, X_n$ be an i.i.d. sample from $U[0, \\theta]$ and $\\widehat\\theta = X_{(n)}$. Is this estimation unbiased? Asymptotically unbiased? Consistent?\n",
    "\n",
    "2. Show that estimation $\\widehat{\\theta}_n$ is consistent if it is asymptotically unbiased and  $\\lim\\limits_{n\\to\\infty}\\mathbb{V}(\\widehat{\\theta}_n) = 0$.\n",
    "\n",
    "3. Let $X_1, \\ldots, X_n$ be an i.i.d. sample from $U[0, 2\\theta]$. Show that sample median $\\mathrm{med}(X_1, \\ldots, X_n)$ is unbiased estimation of $\\theta$.\n",
    "\n",
    "4. Let $X_1, \\ldots, X_n$ be an i.i.d. sample from a distribution with finite moments $\\mathbb EX_1$ and $\\mathbb EX_1^2$. Is sample variance $\\overline S_n$ unbiased estimation of $\\theta = \\mathbb V X_1$? Asymptotically unbiased?\n",
    "\n",
    "5. There are $k$ heads and $n-k$ tails in $n$ independent Bernoulli trials. Find MLE of the probability of heads.\n",
    "\n",
    "6. Find MLE estimation of $\\lambda$ if $X_1, \\ldots, X_n$ is an i.i.d. sample from $\\mathrm{Pois}(\\lambda)$.\n",
    "\n",
    "7. Let $X_1, \\ldots, X_n$ be i.i.d. sample from $\\mathcal N(\\mu, \\tau)$. Find MLE of $\\mu$ and $\\tau$.\n",
    "\n",
    "8. Find MLE estimation of $a$ and $b$ if $X_1, \\ldots, X_n \\sim U[a, b]$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
