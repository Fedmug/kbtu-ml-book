{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectors\n",
    "\n",
    "В школе учат, что вектор — это направленный отрезок. Такую геометрическую интерпретацию вектора полезно иметь в виду, однако, в прикладных задачах, связанных с машинным обучением и анализом данных, на вектор смотрят как на упорядоченный набор чисел. Его можно записать двумя способами: в строчку или в столбик. Традиция такова, что по умолчанию вектор считается вектором-столбцом, если не оговорено иное. В этом учебнике мы будем придерживаться следующих конвенций:\n",
    "\n",
    "* векторы обозначаются строчными жирными буквами: $\\boldsymbol x$, $\\boldsymbol y$, $\\boldsymbol u$, $\\boldsymbol v$, $\\boldsymbol a$, $\\boldsymbol b, \\ldots$;\n",
    "* по умолчанию подразумевается, что вектор $\\boldsymbol x$ — это вектор-столбец:\n",
    "\n",
    "$$\n",
    "\\boldsymbol x =  \\begin{pmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{pmatrix};\n",
    "$$\n",
    "\n",
    "* для записи в строчку вектор-столбец $\\boldsymbol x$ надо **транспонировать**: \n",
    "\n",
    "    $$\n",
    "    \\boldsymbol x^\\top = (x_1, \\ldots, x_n);\n",
    "    $$\n",
    "\n",
    "* зачастую направление записи вектора (в строчку или в столбец) не имеет существенного значения, и тогда для экономии места вполне допустима запись $\\boldsymbol x = (x_1, \\ldots, x_n)$.\n",
    "\n",
    "Компоненты вектора $\\boldsymbol x = (x_1, \\ldots, x_n)$ называются его **координатами**. Обычно подразумевается, что компоненты вектора — это действительные числа, и поэтому пространство числовых векторов с $n$ координатами обозначают $\\mathbb R^n$. \n",
    "\n",
    "## Vectors in Python\n",
    "\n",
    "For numeric operations with matrices and vectors in Python there is [NumPy](https://numpy.org/) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 7]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "vector = np.array([1, 2, 7])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute `dtype` specifies the underlying type of the vector's elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(vector.dtype)\n",
    "float_vector = np.array([-0.1, 1.123])\n",
    "print(float_vector.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector operations\n",
    "\n",
    "Над векторами определены две основные операции.\n",
    "\n",
    "1. Сложение векторов: если\n",
    "\n",
    "    $$\n",
    "    \\boldsymbol x =  \\begin{pmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{pmatrix}, \\quad\n",
    "    \\boldsymbol y =  \\begin{pmatrix} y_1 \\\\ \\vdots \\\\ y_n \\end{pmatrix},\n",
    "    \\text{ то }\n",
    "    \\boldsymbol x + \\boldsymbol y =  \\begin{pmatrix} x_1 + y_1 \\\\ \\vdots \\\\ x_n + y_n \\end{pmatrix}.\n",
    "    $$\n",
    "\n",
    "2. Умножение вектора на скаляр (число): если\n",
    "\n",
    "    $$\n",
    "    \\boldsymbol x =  \\begin{pmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{pmatrix},\\quad\n",
    "    \\alpha \\in \\mathbb R,\n",
    "    \\text{ то } \n",
    "    \\alpha \\boldsymbol x =  \\begin{pmatrix} \\alpha x_1 \\\\ \\vdots \\\\ \\alpha x_n \\end{pmatrix}.\n",
    "    $$ \n",
    "\n",
    "**Нулевой вектор** $\\boldsymbol 0$, все координаты которого равны нулю, обладает свойством $\\boldsymbol x + \\boldsymbol 0 = \\boldsymbol x$, $\\boldsymbol x \\in \\mathbb R^n$.\n",
    "\n",
    "Вектор $-\\boldsymbol x = (-1)\\cdot \\boldsymbol x$ называется **противоположным вектором** для вектора $\\boldsymbol x$. Вычитание векторов сводится к добавлению противоположного вектора: $\\boldsymbol y - \\boldsymbol x = \\boldsymbol y + (-\\boldsymbol x)$.\n",
    "\n",
    "Векторы $\\boldsymbol x$ и $\\boldsymbol y$ **коллинеарны**, если $\\boldsymbol y = \\alpha \\boldsymbol x$ при некотором $\\alpha \\in \\mathbb R$. Геометрически это означает, что коллинеарные векторы лежат на одной прямой, проходящей через начало координат.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In NumPy all these operations are straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.25 0.5  0.75 1.  ]\n",
      "[1 2 3 4 5]\n",
      "Zero vector: [0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "x = np.linspace(0, 1, num=5)\n",
    "y = np.arange(1, 6)\n",
    "z = np.zeros(5)\n",
    "print(x)\n",
    "print(y)\n",
    "print(\"Zero vector:\", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum: [1.   2.25 3.5  4.75 6.  ]\n",
      "Diff: [1.   1.75 2.5  3.25 4.  ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sum:\", x+y)\n",
    "print(\"Diff:\", y-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -2 -3 -4 -5]\n"
     ]
    }
   ],
   "source": [
    "print(-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector norm\n",
    "\n",
    "Под **длиной**, или **нормой**, вектора $\\boldsymbol x = (x_1, \\ldots, x_n)$ чаще всего понимают величину\n",
    "\n",
    "$$\n",
    "    \\Vert \\boldsymbol x \\Vert = \\sqrt{\\sum\\limits_{k=1}^n x_k^2}.\n",
    "$$\n",
    "\n",
    "Это так называемая **евклидова норма** вектора $\\boldsymbol x$, представляющая собой обобщение теоремы Пифагора на случай $\\mathbb R^n$. \n",
    "\n",
    "<!--\n",
    "Вообще нормой вектора $\\boldsymbol x \\in \\mathbb R^n$ называется функция $\\Vert\\cdot \\Vert \\colon \\mathbb R^n \\to [0, +\\infty)$ со следующими свойствами:\n",
    "\n",
    "1. $\\Vert\\boldsymbol x\\Vert \\geqslant 0$, $\\Vert\\boldsymbol x\\Vert = 0 \\iff \\boldsymbol x =\\boldsymbol 0$;\n",
    "\n",
    "2. $\\Vert\\alpha \\boldsymbol x \\Vert = \\vert\\alpha\\vert \\Vert\\boldsymbol x \\Vert$ для всех $\\alpha \\in \\mathbb R$, $\\boldsymbol x \\in \\mathbb R^n$;\n",
    "\n",
    "3. $\\Vert\\boldsymbol x + \\boldsymbol y\\Vert \\leqslant \\Vert\\boldsymbol x \\Vert + \\Vert\\boldsymbol y \\Vert$ для всех $\\boldsymbol x, \\boldsymbol y \\in \\mathbb R^n$ (неравенство треугольника).\n",
    "-->\n",
    "Евклидова норма является частным случаем **$p$-нормы** (или **нормы Минковского**)\n",
    "\n",
    "$$\n",
    "    \\Vert \\boldsymbol x \\Vert_p = \\bigg(\\sum\\limits_{k=1}^n |x_k|^p \\bigg)^\\frac 1p, \\quad p \\geqslant 1.\n",
    "$$\n",
    "\n",
    "<!--\n",
    "Неравенство треугольника для $p$-нормы вытекает из [неравенства Минковского](https://ru.wikipedia.org/wiki/%D0%9D%D0%B5%D1%80%D0%B0%D0%B2%D0%B5%D0%BD%D1%81%D1%82%D0%B2%D0%BE_%D0%9C%D0%B8%D0%BD%D0%BA%D0%BE%D0%B2%D1%81%D0%BA%D0%BE%D0%B3%D0%BE#%D0%A7%D0%B0%D1%81%D1%82%D0%BD%D1%8B%D0%B5_%D1%81%D0%BB%D1%83%D1%87%D0%B0%D0%B8). Тут важно, что $p \\geqslant 1$, в противном случае неравенство треугольника не выполняется, и $p$-норма уже больше не норма.\n",
    "-->\n",
    "\n",
    "Норма Минковского превращается в\n",
    "\n",
    "* евклидову норму при $p=2$;\n",
    "\n",
    "* **манхэттенскую** норму $\\Vert \\boldsymbol x \\Vert_1 = \\sum\\limits_{k=1}^n \\vert x_k \\vert$ при $p=1$;\n",
    "\n",
    "* **максимальную** норму $\\Vert \\boldsymbol x \\Vert_\\infty = \\max \\{\\vert x_1 \\vert, \\ldots, \\vert x_n \\vert\\}$ при $p\\to\\infty$.\n",
    "\n",
    "**Упражнение**. Пусть $\\boldsymbol x \\in \\mathbb R^n$. Докажите следующие неравенства:\n",
    "\n",
    "1. $\\Vert \\boldsymbol x \\Vert_\\infty \\leqslant \\Vert \\boldsymbol x \\Vert_1 \\leqslant n\\Vert \\boldsymbol x \\Vert_\\infty$;\n",
    "\n",
    "2. $\\Vert \\boldsymbol x \\Vert_\\infty \\leqslant \\Vert \\boldsymbol x \\Vert_2 \\leqslant \\sqrt{n}\\Vert \\boldsymbol x \\Vert_\\infty$;\n",
    "\n",
    "3. $\\Vert \\boldsymbol x \\Vert_2 \\leqslant \\Vert \\boldsymbol x \\Vert_1 \\leqslant \\sqrt{n}\\Vert \\boldsymbol x \\Vert_2$.\n",
    "\n",
    "```{admonition} Solution\n",
    ":class: tip, dropdown\n",
    "Соотношения 1 и 2 немедленно следуют из неравенств\n",
    "\n",
    "$$\n",
    "    \\max\\{a_1, \\ldots, a_n\\} \\leqslant \\sum\\limits_{k=1}^n a_k \\leqslant n\\max\\{a_1, \\ldots, a_n\\},\n",
    "$$\n",
    "\n",
    "справедливых для любых неотрицательных чисел $a_1, \\ldots, a_n$. Неравенство $\\Vert \\boldsymbol x \\Vert_2 \\leqslant \\Vert \\boldsymbol x \\Vert_1$ эквивалентно неравенству\n",
    "\n",
    "$$\n",
    "    \\sum\\limits_{k=1}^n x_k^2 \\leqslant \\Big(\\sum\\limits_{k=1}^n \\vert x_k\\vert\\Big)^2 =  \\sum\\limits_{k=1}^n x_k^2 + \\underbrace{2\\sum\\limits_{1\\leqslant i < j\\leqslant n} \\vert x_i\\vert \\vert x_j\\vert}_{\\geqslant 0},\n",
    "$$\n",
    "\n",
    "которое, очевидно, выполнено. Наконец, последнее неравенство вытекает из неравенства \n",
    "Коши—Буняковского—Шварца.\n",
    "\n",
    "$$\n",
    "    \\Vert \\boldsymbol x \\Vert_1 = \\sum\\limits_{k=1}^n 1\\cdot\\vert x_k\\vert \\leqslant \\sqrt{\\sum\\limits_{k=1}^n 1^2}\\sqrt{\\sum\\limits_{k=1}^n \\vert x_k\\vert^2} = \\sqrt n \\Vert \\boldsymbol x \\Vert_2.\n",
    "$$\n",
    "```\n",
    "\n",
    "**Упражнение**. Докажите, что $p$-норма при $1\\leqslant p \\leqslant \\infty$ удовлетворяет следующим свойствам:\n",
    "\n",
    "1. $\\Vert\\boldsymbol x\\Vert \\geqslant 0$, $\\Vert\\boldsymbol x\\Vert = 0 \\iff \\boldsymbol x =\\boldsymbol 0$;\n",
    "\n",
    "2. $\\Vert\\alpha \\boldsymbol x \\Vert = \\vert\\alpha\\vert \\Vert\\boldsymbol x \\Vert$ для всех $\\alpha \\in \\mathbb R$, $\\boldsymbol x \\in \\mathbb R^n$;\n",
    "\n",
    "3. $\\Vert\\boldsymbol x + \\boldsymbol y\\Vert \\leqslant \\Vert\\boldsymbol x \\Vert + \\Vert\\boldsymbol y \\Vert$ для всех $\\boldsymbol x, \\boldsymbol y \\in \\mathbb R^n$ (неравенство треугольника).\n",
    "\n",
    "```{admonition} Solution\n",
    ":class: tip, dropdown\n",
    "Первые два свойства легко проверяются напрямую. Свойство 3 для $p=1$ и $p=\\infty$ следует из неравенства $\\vert a+b\\vert \\leqslant \\vert a\\vert + \\vert b \\vert$. Для остальных значений $p$ неравенство треугольника эквивалентно [неравенству Минковского](https://ru.wikipedia.org/wiki/%D0%9D%D0%B5%D1%80%D0%B0%D0%B2%D0%B5%D0%BD%D1%81%D1%82%D0%B2%D0%BE_%D0%9C%D0%B8%D0%BD%D0%BA%D0%BE%D0%B2%D1%81%D0%BA%D0%BE%D0%B3%D0%BE#%D0%A7%D0%B0%D1%81%D1%82%D0%BD%D1%8B%D0%B5_%D1%81%D0%BB%D1%83%D1%87%D0%B0%D0%B8){:target=\"_blank\"}.\n",
    "```\n",
    "\n",
    "Три свойства из последнего упражнения являются аксиомами нормы в $\\mathbb R^n$. Иначе говоря, всякая функция $\\Vert\\cdot \\Vert \\colon \\mathbb R^n \\to [0, +\\infty)$, удовлетворяющая этим трём свойством, по определению называется нормой. В частности, $p$-норма является нормой при $1\\leqslant p \\leqslant \\infty$. Отметим, что $p$-норма перестаёт быть нормой при $p<1$, поскольку неравенство треугольника в таком случае не выполняется.\n",
    "\n",
    "Вектор $\\boldsymbol x$ называется **единичным**, если его норма равна единице: $\\Vert \\boldsymbol x\\Vert = 1$. **Единичным шаром** в $\\mathbb R^n$ называется множество\n",
    "\n",
    "$$\n",
    "    \\{\\boldsymbol x \\in \\mathbb R^n\\colon \\Vert \\boldsymbol x \\Vert \\leqslant 1\\}.\n",
    "$$\n",
    "\n",
    "Для случая евклидовой нормы это действительно шар при $n=3$ (круг при $n=2$). Единичные шары для $p$-нормы при различных значениях $p$ изображены на рисунке ниже.\n",
    "\n",
    "\n",
    "Расстояние между векторами $\\boldsymbol x$ и $\\boldsymbol y$ вычисляется по формуле $\\Vert \\boldsymbol x - \\boldsymbol y\\Vert$. Норма здесь может быть любой, наиболее популярный выбор — опять же евклидова норма $\\Vert\\boldsymbol x - \\boldsymbol y\\Vert_2$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to calculate norm in NumPy? Use [np.linalg.norm](https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, -2])\n",
    "np.linalg.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To specify $p$ use parameter `ord`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-norm = 5.0\n",
      "2-norm = 3.0\n",
      "10-norm = 2.143651567459133\n",
      "infinite norm = 2.0\n"
     ]
    }
   ],
   "source": [
    "print(\"1-norm =\", np.linalg.norm(x, ord=1))\n",
    "print(\"2-norm =\", np.linalg.norm(x, ord=2))\n",
    "print(\"10-norm =\", np.linalg.norm(x, ord=10))\n",
    "print(\"infinite norm =\", np.linalg.norm(x, ord=np.inf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner product\n",
    "\n",
    "**Скалярным произведением** векторов $\\boldsymbol x, \\boldsymbol y \\in \\mathbb R^n$ называется величина\n",
    "\n",
    "$$\n",
    "    \\langle \\boldsymbol x, \\boldsymbol y \\rangle = \\sum\\limits_{k=1}^n x_k y_k.\\tag{1}\n",
    "$$ \n",
    "\n",
    "Альтернативное обозначение: $\\boldsymbol x^\\top \\boldsymbol y$ (объяснение этого обозначения см. в одной из [следующих секций](#умножение-матрицы-на-вектор)). \n",
    "\n",
    "<!--\n",
    "Скалярное произведение является функцией $\\langle \\cdot, \\cdot \\rangle \\colon \\mathbb R^n\\times \\mathbb R^n \\to \\mathbb R$ со следующими свойствами:\n",
    "\n",
    "1. $\\langle \\boldsymbol x, \\boldsymbol x \\rangle \\geqslant 0$, $\\langle \\boldsymbol x, \\boldsymbol x \\rangle = 0 \\iff \\boldsymbol x = \\boldsymbol 0$ (положительная определённость);\n",
    "\n",
    "2. $\\langle \\boldsymbol x, \\boldsymbol y \\rangle = \\langle \\boldsymbol y, \\boldsymbol x \\rangle$ (симметричность);\n",
    "\n",
    "3. $\\langle \\alpha\\boldsymbol x + \\beta\\boldsymbol y, \\boldsymbol z \\rangle = \\alpha \\langle \\boldsymbol x, \\boldsymbol z \\rangle + \\beta \\langle \\boldsymbol y, \\boldsymbol z \\rangle$ (линейность).\n",
    "\n",
    "Нетрудно проверить, что определённое по формуле (1) стандартное скалярное произведение в $\\mathbb R^n$ удовлетворяет всем этим свойствам. Существуют и другие виды скалярных произведений, но на практике они редко находят применение.\n",
    "\n",
    "\n",
    "Скалярное произведение автоматически порождает норму по формуле $\\Vert \\boldsymbol x \\Vert = \\sqrt{\\langle \\boldsymbol x, \\boldsymbol x \\rangle}$. Первые два свойства такой нормы немедленно вытекают из определения скалярного произведения, а \n",
    "-->\n",
    "\n",
    "Скалярное произведение порождает евклидову норму в $\\mathbb R^n$: \n",
    "\n",
    "$$\n",
    "\\sqrt{\\langle \\boldsymbol x, \\boldsymbol x \\rangle} = \\Vert \\boldsymbol x \\Vert_2.\n",
    "$$\n",
    "\n",
    "**Упражнение**. Докажите неравенство Коши—Буняковского—Шварца\n",
    "\n",
    "$$\n",
    "    \\bigg(\\sum\\limits_{k=1}^n x_k y_k\\bigg)^2 \\leqslant \\sum\\limits_{k=1}^n x_k^2 \\sum\\limits_{k=1}^n y_k^2, \n",
    "$$\n",
    "\n",
    "<details>\n",
    "<summary markdown=\"span\">Решение </summary>\n",
    "<div>\n",
    "\n",
    "[Здесь](https://rgmia.org/papers/v12e/Cauchy-Schwarzinequality.pdf){:target=\"_blank\"} можно найти 12 различных доказательств этого замечательного неравенства. Вот первое из них:\n",
    "\n",
    "$$\n",
    "    \\begin{multline*}\n",
    "    0\\leqslant \\sum\\limits_{i, j=1}^n (x_i y_j - x_j y_i)^2 = \\\\\n",
    "    =\\sum\\limits_{i=1}^n x_i^2 \\sum\\limits_{j=1}^n y_j^2 + \\sum\\limits_{i=1}^n y_i^2 \\sum\\limits_{j=1}^n x_j^2 - 2  \\sum\\limits_{i=1}^n x_i y_i\\sum\\limits_{j=1}^n x_j y_j = \\\\\n",
    "    =2\\sum\\limits_{i=1}^n x_i^2 \\sum\\limits_{j=1}^n y_j^2 - 2\\bigg(\\sum\\limits_{i=1}^n x_i y_i\\bigg)^2,\n",
    "    \\end{multline*}\n",
    "$$\n",
    "\n",
    "откуда и вытекает требуемое. Из приведённого рассуждения также следует, что неравенство Коши—Буняковского—Шварца обращается в равенство в следующих случаях:\n",
    "\n",
    "* $x_i = 0$ при всех $i=1, \\ldots, n$;\n",
    "* $y_i = 0$ при всех $i=1, \\ldots, n$;\n",
    "* $\\frac{x_i}{y_i} = C$ при всех $i=1, \\ldots, n$.\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "\n",
    "С учётом введённых выше определений евклидовой нормы и скалярного произведения неравенство Коши—Буняковского—Шварца можно переписать в виде\n",
    "\n",
    "$$\n",
    "    \\vert\\langle \\boldsymbol x, \\boldsymbol y \\rangle\\vert \\leqslant \\Vert \\boldsymbol x \\Vert \\cdot \\Vert \\boldsymbol y \\Vert.\n",
    "$$\n",
    "\n",
    "Это неравенство обращается в равенство тогда и только тогда, когда векторы $\\boldsymbol x$ и $\\boldsymbol y$ коллинеарны.\n",
    "\n",
    "Если скалярное произведение векторов $\\boldsymbol x$ и $\\boldsymbol y$ равно нулю, то они называются **ортогональными**. Угол $\\theta$ между двумя ненулевыми векторами $\\boldsymbol x$ и $\\boldsymbol y$ определяется из соотношения\n",
    "\n",
    "$$\n",
    "    \\cos \\theta = \\frac{\\langle \\boldsymbol x, \\boldsymbol y \\rangle}{\\Vert \\boldsymbol x\\Vert \\cdot \\Vert \\boldsymbol y\\Vert}.\n",
    "$$\n",
    "\n",
    "В силу неравенства Коши—Буняковского—Шварца эта дробь всегда находится в диапазоне от $-1$ до $1$, поэтому такое определение угла между векторами корректно.\n",
    "Если $\\langle \\boldsymbol x, \\boldsymbol y \\rangle = 0$, то $\\cos\\theta = 0$ и $\\theta = \\frac \\pi 2$. Таким образом, угол между ортогональными векторами равен $90°$.\n",
    "\n",
    "В анализе данных косинус угла между векторами часто берут в качестве меры их близости (**cosine similarity**): чем ближе $\\cos\\theta$ к единице, тем более похожими считаются вектора. Похожая метрика **косинусное расстояние** (**cosine distance**) определяется по формуле $1-\\cos\\theta$.\n",
    "\n",
    "Отметим, что для вычисления скалярного произведения по формуле (1) требуется выполнить $n$ умножений и $n-1$ сложение. Если измерять трудоёмкость подсчёта скалярного произведения $n$-мерных векторов в количестве арифметических операций, то она составит $O(n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(inner-python)=\n",
    "### Dot product in NumPy\n",
    "There are several way to calculate the inner product of two vectors in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3 3\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "y = np.array([1, -2, 2])\n",
    "print(np.dot(x, y), x.dot(y), x @ y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
