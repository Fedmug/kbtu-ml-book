[
    {
        "question": "What is the primary function of loading vectors $\\phi$ in PCA?",
        "type": "multiple_choice",
        "answers": [
            {
                "answer": "Guide dimensionality reduction",
                "correct": false,
                "feedback": "Incorrect.. Try again."
            },
            {
                "answer": "Determine variable means",
                "correct": false,
                "feedback": "Incorrect.. Try again."
            },
            {
                "answer": "Weigh original variables for principal components",
                "correct": true,
                "feedback": "Correct"
            },
            {
                "answer": "Introduce inconsistency",
                "correct": false,
                "feedback": "Incorrect.. Try again."
            }
        ]
    },
    {
      "question": "In PCA, what condition is imposed on the loading vector ($\\phi_{11}$, $\\phi_{12}$, ..., $\\phi_{1p}$) to prevent an increase in variance solely by magnifying the $\\phi_{j_1}$ values for the first component $Z_1$?",

      "type": "numeric",
      "answers": [
        {
          "type": "value",
          "value": 1,
          "correct": true,
          "feedback": "Correct."
        },
        {
          "type": "range",
          "range": [
            -100000000,
            -1
          ],
          "correct": false,
          "feedback": "Incorrect. Try again."
        },
        {
          "type": "default",
          "feedback": "Incorrect. Try again."
        }
      ]
    },
    {
        "question": "Which of the following is a reasonable way to select the number of principal components \\k\n (Recall that n is the dimensionality of the input data and m is the number of input examples.)",
        "type": "multiple_choice",
        "answers": [
            {
                "answer": "Choose \\k to be the smallest value so that at least 99% of the variance is retained.",
                "correct": true,
                "feedback": "Correct, this maintatins the structure of the data while maximally reducing its dimension."
            },
            {
                "answer": "Choose \\k to be 99% of m (i.e, \\k = 0.99 * \\m, rounded to the nearest integer).",
                "correct": false,
                "feedback": "Incorrect.. Try again."
            },
            {
                "answer": "Choose \\k to be the largest value so that at least 99% of the variance is retained",
                "correct": false,
                "feedback": "Incorrect.. Try again."
            },
            {
                "answer": "Use the elbow method",
                "correct": false,
                "feedback": "Incorrect.. Try again."
            }
        ]
    },
    {
        "question": "What are the benefits of Principal Component Analysis (PCA)?",
        "type": "multiple_choice",
        "answers": [
            {
                "answer": "Reduces high-dimensional data complexity",
                "correct": true,
                "feedback": "Correct. PCA effectively reduces high-dimensional data complexity."
            },
            {
                "answer": "Enables clear visualization by transforming data",
                "correct": true,
                "feedback": "Correct. PCA enables clear visualization by transforming high-dimensional data."
            },
            {
                "answer": "Enhances the signal-to-noise ratio for improved clarity",
                "correct": true,
                "feedback": "Correct. PCA emphasizes principal components with high variance for noise reduction."
            },
            {
                "answer": "Identifies outliers in the dataset",
                "correct": false,
                "feedback": "Incorrect. PCA is not primarily used for identifying outliers."
            },
            {
                "answer": "Generates 3D visualizations",
                "correct": false,
                "feedback": "Incorrect. While PCA can be used for visualization, its primary purpose is dimensionality reduction, not specifically 3D visualizations."
            }
        ]
    },
     {
        "question": "Which of the following are recommended applications of PCA? Select all that apply.",
        "type": "multiple_choice",
        "answers": [
          {
            "answer": "Data visualization: Represent 2D data in a different plot using PCA with k=2.",
            "correct": false,
            "feedback": "Incorrect. Try again."
          },
          {
            "answer": "Replacement for linear regression: PCA and linear regression often yield similar results.",
            "correct": false,
            "feedback": "Incorrect. Try again."
          },
          {
            "answer": "Dimensionality reduction for supervised learning: Reduce input data dimensionality for faster learning algorithms.",
            "correct": true,
            "feedback": "PCA is useful when the input dimensionality is high, making the learning algorithm slow."
          },
          {
            "answer": "Data compression: Reduce data dimensionality to save memory/disk space.",
            "correct": true,
            "feedback": "PCA allows saving space at the cost of losing some data informationâ€”a reasonable tradeoff when resources are limited."
          }
        ]
    }
]